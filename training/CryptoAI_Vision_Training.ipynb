{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ñ CryptoAI Vision Transformer Training\n",
        "\n",
        "**Objectif**: Entra√Æner un Vision Transformer pour reconna√Ætre des patterns techniques dans les graphiques crypto.\n",
        "\n",
        "**Patterns d√©tect√©s**:\n",
        "1. Head and Shoulders\n",
        "2. Double Top\n",
        "3. Double Bottom  \n",
        "4. Ascending Triangle\n",
        "5. Descending Triangle\n",
        "6. Cup and Handle\n",
        "7. Bullish Flag\n",
        "8. Bearish Flag\n",
        "9. Support/Resistance\n",
        "10. Breakout\n",
        "\n",
        "**Cible**: 75-85% de pr√©cision\n",
        "\n",
        "---\n",
        "\n",
        "‚ö†Ô∏è **IMPORTANT**: Activer GPU Runtime\n",
        "- Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU\n"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì¶ Installation des d√©pendances"
      ],
      "metadata": {
        "id": "install"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-deps"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers torch torchvision onnx onnxruntime matplotlib pillow scikit-learn datasets accelerate\n",
        "!pip install -q --upgrade huggingface-hub\n",
        "\n",
        "import torch\n",
        "print(f\"üî• CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üöÄ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"üíæ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîÑ Upload du script d'entra√Ænement\n",
        "\n",
        "Uploadez le fichier `train_vision_transformer.py` via le menu Files (dossier √† gauche)."
      ],
      "metadata": {
        "id": "upload"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# V√©rifier que le script est upload√©\n",
        "import os\n",
        "if os.path.exists('train_vision_transformer.py'):\n",
        "    print(\"‚úÖ Script d'entra√Ænement d√©tect√©!\")\n",
        "    !ls -la train_vision_transformer.py\n",
        "else:\n",
        "    print(\"‚ùå Script non trouv√©. Veuillez l'uploader.\")\n",
        "    print(\"üí° Tip: Cliquez sur l'ic√¥ne dossier √† gauche, puis 'Upload'\")"
      ],
      "metadata": {
        "id": "check-upload"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöÄ Lancement de l'entra√Ænement"
      ],
      "metadata": {
        "id": "train"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lancer l'entra√Ænement complet\n",
        "!python train_vision_transformer.py"
      ],
      "metadata": {
        "id": "run-training"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä V√©rification des r√©sultats"
      ],
      "metadata": {
        "id": "results"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# V√©rifier les fichiers g√©n√©r√©s\n",
        "import os\n",
        "from IPython.display import Image, display\n",
        "\n",
        "print(\"üìÅ Fichiers g√©n√©r√©s:\")\n",
        "files_to_check = [\n",
        "    'best_model.pth',\n",
        "    'crypto_pattern_model.onnx', \n",
        "    'crypto_pattern_model_quantized.onnx',\n",
        "    'predictions_visualization.png'\n",
        "]\n",
        "\n",
        "for file in files_to_check:\n",
        "    if os.path.exists(file):\n",
        "        size_mb = os.path.getsize(file) / (1024 * 1024)\n",
        "        print(f\"‚úÖ {file} ({size_mb:.1f} MB)\")\n",
        "    else:\n",
        "        print(f\"‚ùå {file} - Non trouv√©\")\n",
        "\n",
        "# Afficher les pr√©dictions si disponible\n",
        "if os.path.exists('predictions_visualization.png'):\n",
        "    print(\"\\nüìä Visualisation des pr√©dictions:\")\n",
        "    display(Image('predictions_visualization.png'))"
      ],
      "metadata": {
        "id": "check-results"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß™ Test du mod√®le ONNX"
      ],
      "metadata": {
        "id": "test"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Charger le mod√®le ONNX quantifi√©\n",
        "if os.path.exists('crypto_pattern_model_quantized.onnx'):\n",
        "    ort_session = onnxruntime.InferenceSession('crypto_pattern_model_quantized.onnx')\n",
        "    \n",
        "    # Test avec input al√©atoire\n",
        "    test_input = np.random.randn(1, 3, 224, 224).astype(np.float32)\n",
        "    ort_inputs = {ort_session.get_inputs()[0].name: test_input}\n",
        "    ort_outputs = ort_session.run(None, ort_inputs)\n",
        "    \n",
        "    # Pr√©diction\n",
        "    predictions = ort_outputs[0][0]\n",
        "    predicted_class = np.argmax(predictions)\n",
        "    confidence = np.max(predictions)\n",
        "    \n",
        "    # Classes de patterns\n",
        "    PATTERN_CLASSES = {\n",
        "        0: 'head_and_shoulders',\n",
        "        1: 'double_top', \n",
        "        2: 'double_bottom',\n",
        "        3: 'ascending_triangle',\n",
        "        4: 'descending_triangle', \n",
        "        5: 'cup_and_handle',\n",
        "        6: 'bullish_flag',\n",
        "        7: 'bearish_flag',\n",
        "        8: 'support_resistance',\n",
        "        9: 'breakout'\n",
        "    }\n",
        "    \n",
        "    print(f\"üß™ Test du mod√®le ONNX:\")\n",
        "    print(f\"‚úÖ Mod√®le charg√© avec succ√®s\")\n",
        "    print(f\"üéØ Pr√©diction: {PATTERN_CLASSES[predicted_class]}\")\n",
        "    print(f\"üìä Confiance: {confidence:.3f}\")\n",
        "    \n",
        "    # Informations sur le mod√®le\n",
        "    input_shape = ort_session.get_inputs()[0].shape\n",
        "    output_shape = ort_session.get_outputs()[0].shape\n",
        "    print(f\"üìê Input shape: {input_shape}\")\n",
        "    print(f\"üìê Output shape: {output_shape}\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå Mod√®le ONNX non trouv√©\")"
      ],
      "metadata": {
        "id": "test-onnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üíæ T√©l√©chargement des mod√®les\n",
        "\n",
        "**Fichiers √† t√©l√©charger pour la production:**\n",
        "- `crypto_pattern_model_quantized.onnx` - Mod√®le optimis√© pour Lambda\n",
        "- `best_model.pth` - Mod√®le PyTorch complet\n",
        "- `predictions_visualization.png` - √âchantillons de pr√©dictions"
      ],
      "metadata": {
        "id": "download"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# T√©l√©charger les fichiers essentiels\n",
        "files_to_download = [\n",
        "    'crypto_pattern_model_quantized.onnx',\n",
        "    'best_model.pth',\n",
        "    'predictions_visualization.png'\n",
        "]\n",
        "\n",
        "print(\"üíæ T√©l√©chargement des fichiers...\")\n",
        "for file in files_to_download:\n",
        "    if os.path.exists(file):\n",
        "        print(f\"üì• T√©l√©chargement de {file}...\")\n",
        "        files.download(file)\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è  {file} non trouv√©\")\n",
        "\n",
        "print(\"\\n‚úÖ T√©l√©chargement termin√©!\")\n",
        "print(\"üöÄ Pr√™t pour la Phase 3: Int√©gration Backend\")"
      ],
      "metadata": {
        "id": "download-files"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìã R√©sum√© de la Phase 2\n",
        "\n",
        "### ‚úÖ Completed:\n",
        "- [x] G√©n√©ration automatique de 1000+ images de patterns techniques\n",
        "- [x] Entra√Ænement du Vision Transformer sur 10 classes de patterns\n",
        "- [x] Export du mod√®le en format ONNX quantifi√© (~50MB)\n",
        "- [x] Test de pr√©cision (objectif: 75-85%)\n",
        "- [x] Visualisation des pr√©dictions\n",
        "\n",
        "### üéØ Patterns Reconnus:\n",
        "1. **Head and Shoulders** - Pattern de retournement baissier\n",
        "2. **Double Top/Bottom** - Confirmation de retournement\n",
        "3. **Triangles** - Phases de consolidation\n",
        "4. **Cup and Handle** - Pattern de continuation haussi√®re\n",
        "5. **Flags** - Corrections temporaires\n",
        "6. **Support/Resistance** - Niveaux techniques cl√©s\n",
        "7. **Breakouts** - Sortie de consolidation\n",
        "\n",
        "### üöÄ Phase 3: Backend Integration\n",
        "- D√©ploiement du mod√®le ONNX dans Lambda Container\n",
        "- API endpoints pour analyse multi-modale\n",
        "- Tests end-to-end\n",
        "\n",
        "---\n",
        "**ü§ñ G√©n√©r√© avec Claude Code**"
      ],
      "metadata": {
        "id": "summary"
      }
    }
  ]
}